{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc48e87-63bf-4da0-9338-b97a53c958bc",
   "metadata": {},
   "source": [
    "## 检查模型和给定的权重是否匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd516bb-8f91-454b-8fcc-08899b3b7d18",
   "metadata": {},
   "source": [
    "### Resnet-MTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d24c4-9afc-4925-b650-172a94992502",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6996f448-7d56-4e03-a54b-c7d3ca2d824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 输入模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "## input_channels = [256,512,1024,2048]\n",
    "## attention_channels = 2048\n",
    "\n",
    "\n",
    "\n",
    "class MTB(nn.Module):\n",
    "    def __init__(self,in_channel,input_channels,attention_channels,outchannels):\n",
    "        super(MTB, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        ## 定义多个channels，得到多尺度特征【Batch，256，1】，【Batch，512，1】，【Batch，1024，1】，【Batch，2048，1】\n",
    "        self.conv1 =  nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part = nn.Sequential(\n",
    "\n",
    "                nn.Conv1d(in_channels=in_channel, out_channels=i, kernel_size=1),\n",
    "                nn.BatchNorm1d(i),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv1.append(temp_part)\n",
    "\n",
    "        self.conv2 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=i, out_channels=attention_channels, kernel_size=1),\n",
    "                nn.BatchNorm1d(attention_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv2.append(temp_part_2)\n",
    "        self.conv4 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_4 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=attention_channels, out_channels=outchannels, kernel_size=1),\n",
    "                nn.BatchNorm1d(outchannels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv4.append(temp_part_4)\n",
    "\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(in_features=outchannels * len(self.input_channels) * 30, out_features= 2048 ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            \n",
    "    \n",
    "            \n",
    "            nn.Linear(2048,1)\n",
    "     \n",
    "            \n",
    "        )\n",
    "\n",
    "\n",
    "    def  forward(self,x):\n",
    "        outs = [in_channel(x) for in_channel in self.conv1]\n",
    "        outs = [in_channel(outs[idx])for idx,in_channel in enumerate(self.conv2)]\n",
    "\n",
    "        outs = [in_channel(outs[idx]) for idx, in_channel in enumerate(self.conv4)]\n",
    "\n",
    "        input_feature = torch.cat(outs,dim = 1 )\n",
    "        input_feature = input_feature.view(input_feature.shape[0],-1)\n",
    "        outs = self.reg(input_feature)\n",
    "\n",
    "\n",
    "        return outs\n",
    "\n",
    "\n",
    "####　测试部分\n",
    "## 现在我们得到了多个尺度的特征\n",
    "\n",
    "\n",
    "\n",
    "# feature = torch.rand([2,2048,30])\n",
    "# in_channel = 2048\n",
    "# input_channels = [256,512,1024,2048]\n",
    "# attention_channels = 2048\n",
    "# outchannels = 1024\n",
    "# model = MTB(in_channel = in_channel, input_channels=input_channels,attention_channels= attention_channels,outchannels=outchannels)\n",
    "# print(model)\n",
    "# \n",
    "# results = model(feature)\n",
    "# #\n",
    "# print(results.shape)\n",
    "\n",
    "\n",
    "in_channel = 2048\n",
    "input_channels = [256, 512, 1024, 2048]\n",
    "attention_channels = 2048\n",
    "outchannels = 512\n",
    "model = MTB(in_channel=in_channel, input_channels=input_channels, attention_channels=attention_channels,\n",
    "            outchannels=outchannels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399932f5-262f-4a8f-9460-58cf278c8253",
   "metadata": {},
   "source": [
    "#### 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069185eb-4ba8-4410-a00f-0a197150b1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/hy-tmp/Resnet_pth/Epcoh_46_Rmse_6.845022201538086_PCC_0.2333487301766989_CCC_0.13534336370107866.pth\"))  #model.load_state_dict()函数把加载的权重复制到模型的权重中去"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940fc24-ad3a-4394-8bfc-c58ad98f73a1",
   "metadata": {},
   "source": [
    "### Resnet-MTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564e462-9cce-4c65-8f3f-d2ce672ae808",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27209fc0-4d52-480d-be09-1362373931ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "## input_channels = [256,512,1024,2048]\n",
    "## attention_channels = 2048\n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    \"\"\" NonLocalBlock Module\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "\n",
    "        conv_nd = nn.Conv1d\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = self.in_channels // 2\n",
    "\n",
    "        self.ImageAfterASPP_bnRelu = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.DepthAfterASPP_bnRelu = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.R_g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        self.R_theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.R_phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.R_W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.F_g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        self.F_theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.F_phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.F_W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, self_fea, mutual_fea, alpha, selfImage):\n",
    "\n",
    "        if selfImage:\n",
    "\n",
    "            selfNonLocal_fea = self.ImageAfterASPP_bnRelu(self_fea)\n",
    "            mutualNonLocal_fea = self.DepthAfterASPP_bnRelu(mutual_fea)\n",
    "\n",
    "            batch_size = selfNonLocal_fea.size(0)\n",
    "            g_x = self.R_g(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            g_x = g_x.permute(0, 2, 1)\n",
    "            # using mutual feature to generate attention\n",
    "            theta_x = self.F_theta(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            phi_x = self.F_phi(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "            # using self feature to generate attention\n",
    "            self_theta_x = self.R_theta(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_theta_x = self_theta_x.permute(0, 2, 1)\n",
    "            self_phi_x = self.R_phi(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_f = torch.matmul(self_theta_x, self_phi_x)\n",
    "            # add self_f and mutual f\n",
    "            f_div_C = F.softmax(alpha * f + self_f, dim=-1)\n",
    "            y = torch.matmul(f_div_C, g_x)\n",
    "            y = y.permute(0, 2, 1).contiguous()\n",
    "            y = y.view(batch_size, self.inter_channels, *selfNonLocal_fea.size()[2:])\n",
    "            W_y = self.R_W(y)\n",
    "            z = W_y + self_fea\n",
    "            return z\n",
    "\n",
    "        else:\n",
    "            selfNonLocal_fea = self.DepthAfterASPP_bnRelu(self_fea)## [30,2408,1]\n",
    "\n",
    "\n",
    "            mutualNonLocal_fea = self.ImageAfterASPP_bnRelu(mutual_fea)##[30,2048,1]\n",
    "\n",
    "            batch_size = selfNonLocal_fea.size(0) ##30\n",
    "\n",
    "            g_x = self.F_g(selfNonLocal_fea).view(batch_size, self.inter_channels, -1) ##[30,1,1024]\n",
    "            g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "            # using mutual feature to generate attention\n",
    "            theta_x = self.R_theta(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            phi_x = self.R_phi(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "            # using self feature to generate attention\n",
    "            self_theta_x = self.F_theta(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_theta_x = self_theta_x.permute(0, 2, 1)\n",
    "            self_phi_x = self.F_phi(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_f = torch.matmul(self_theta_x, self_phi_x)\n",
    "\n",
    "            # add self_f and mutual f\n",
    "            f_div_C = F.softmax(alpha * f + self_f, dim=-1)\n",
    "            print(g_x.shape)\n",
    "            print(f_div_C.shape)\n",
    "            y = torch.matmul(f_div_C, g_x)\n",
    "            y = y.permute(0, 2, 1).contiguous()\n",
    "            y = y.view(batch_size, self.inter_channels, *selfNonLocal_fea.size()[2:])\n",
    "            W_y = self.F_W(y)\n",
    "            z = W_y + self_fea\n",
    "            return z\n",
    "\n",
    "class MTA(nn.Module):\n",
    "    def __init__(self,in_channel,input_channels,attention_channels,outchannels):\n",
    "        super(MTA, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        ## 定义多个channels，得到多尺度特征【Batch，256，1】，【Batch，512，1】，【Batch，1024，1】，【Batch，2048，1】\n",
    "        self.conv1 =  nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part = nn.Sequential(\n",
    "\n",
    "                nn.Conv1d(in_channels=in_channel, out_channels=i, kernel_size=1),\n",
    "                nn.BatchNorm1d(i),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv1.append(temp_part)\n",
    "\n",
    "        self.conv2 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=i, out_channels=attention_channels, kernel_size=1),\n",
    "                nn.BatchNorm1d(attention_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv2.append(temp_part_2)\n",
    "        ## 通过attetnion 需要将他们对其到同一个尺度 return list[Batch,2048,1] * 4\n",
    "        self.conv3 = nn.Conv1d(in_channels= attention_channels *2,out_channels=2, kernel_size=1)\n",
    "        self.nonblock = NonLocalBlock(in_channels= attention_channels)\n",
    "        self.conv4 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_4 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=attention_channels, out_channels=outchannels, kernel_size=1),\n",
    "                nn.BatchNorm1d(outchannels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv4.append(temp_part_4)\n",
    "\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(in_features=outchannels * len(self.input_channels) * 30, out_features= 2048 ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048,1)\n",
    "        )\n",
    "\n",
    "        # self.conv4 = nn.ModuleList([nn.Conv1d(in_channels= attention_channels,out_channels=outchannels,kernel_size=1) for i in range(len(input_channels))])\n",
    "\n",
    "    def  forward(self,x):\n",
    "        outs = [in_channel(x) for in_channel in self.conv1]\n",
    "        outs = [in_channel(outs[idx])for idx,in_channel in enumerate(self.conv2)]\n",
    "\n",
    "        if len(self.input_channels) == 4:\n",
    "            conncat_tensor_01 = torch.cat([outs[0], outs[1]], dim=1)\n",
    "            conncat_tensor_01_conv = self.conv3(conncat_tensor_01)\n",
    "            alpha_01 = F.softmax(conncat_tensor_01_conv,dim=1)\n",
    "            alpha_01_1 = alpha_01[:,1,:].unsqueeze(dim=2)\n",
    "            feature_attention_0 = self.nonblock(outs[0], outs[1], alpha_01_1, True)\n",
    "\n",
    "            conncat_tensor_12 = torch.cat([outs[1], outs[2]], dim=1)\n",
    "            conncat_tensor_12_conv = self.conv3(conncat_tensor_12)\n",
    "            alpha_12 = F.softmax(conncat_tensor_12_conv, dim=1)\n",
    "            alpha_12_2 = alpha_12[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_1 = self.nonblock(outs[1], outs[2], alpha_12_2, True)\n",
    "\n",
    "            conncat_tensor_23 = torch.cat([outs[2], outs[3]], dim=1)\n",
    "            conncat_tensor_23_conv = self.conv3(conncat_tensor_23)\n",
    "            alpha_23 = F.softmax(conncat_tensor_23_conv, dim=1)\n",
    "            alpha_23_3 = alpha_23[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_2 = self.nonblock(outs[2], outs[3], alpha_23_3, True)\n",
    "\n",
    "            conncat_tensor_30 = torch.cat([outs[3], outs[0]], dim=1)\n",
    "            conncat_tensor_30_conv = self.conv3(conncat_tensor_30)\n",
    "            alpha_30 = F.softmax(conncat_tensor_30_conv, dim=1)\n",
    "            alpha_30_3 = alpha_30[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_3 = self.nonblock(outs[3], outs[0], alpha_30_3, True)\n",
    "\n",
    "            outs = [feature_attention_0, feature_attention_1, feature_attention_2, feature_attention_3]\n",
    "        elif len(self.input_channels) == 3:\n",
    "            conncat_tensor_01 = torch.cat([outs[0], outs[1]], dim=1)\n",
    "            conncat_tensor_01_conv = self.conv3(conncat_tensor_01)\n",
    "            alpha_01 = F.softmax(conncat_tensor_01_conv, dim=1)\n",
    "            alpha_01_1 = alpha_01[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_0 = self.nonblock(outs[0], outs[1], alpha_01_1, True)\n",
    "\n",
    "            conncat_tensor_12 = torch.cat([outs[1], outs[2]], dim=1)\n",
    "            conncat_tensor_12_conv = self.conv3(conncat_tensor_12)\n",
    "            alpha_12 = F.softmax(conncat_tensor_12_conv, dim=1)\n",
    "            alpha_12_2 = alpha_12[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_1 = self.nonblock(outs[1], outs[2], alpha_12_2, True)\n",
    "\n",
    "            conncat_tensor_20 = torch.cat([outs[2], outs[0]], dim=1)\n",
    "            conncat_tensor_20_conv = self.conv2(conncat_tensor_20)\n",
    "            alpha_20 = F.softmax(conncat_tensor_20_conv, dim=1)\n",
    "            alpha_20_2 = alpha_20[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_2 = self.nonblock(outs[2], outs[0], alpha_20_2, True)\n",
    "\n",
    "            outs = [feature_attention_0, feature_attention_1, feature_attention_2]\n",
    "\n",
    "        outs = [in_channel(outs[idx]) for idx, in_channel in enumerate(self.conv4)]\n",
    "\n",
    "        input_feature = torch.cat(outs,dim = 1 )\n",
    "        input_feature = input_feature.view(input_feature.shape[0],-1)\n",
    "        outs = self.reg(input_feature)\n",
    "\n",
    "\n",
    "        return outs\n",
    "\n",
    "\n",
    "####　测试部分\n",
    "## 现在我们得到了多个尺度的特征\n",
    "#\n",
    "# x1 = torch.rand([30,2048,1])\n",
    "# x2 = torch.rand([30,2048,1])\n",
    "# x3 = torch.rand([30,2048,1])\n",
    "# x4 = torch.rand([30,2048,1])\n",
    "# outs = [x1,x2,x3,x4]\n",
    "# ### 1. concat feature\n",
    "#\n",
    "# conncat_tensor_01 = torch.cat([outs[0], outs[1]], dim=1)\n",
    "# print(conncat_tensor_01.shape)\n",
    "# conv1 = nn.Conv1d(in_channels=2048 *2 , out_channels=2, kernel_size=1)\n",
    "# conncat_tensor_01_conv = conv1(conncat_tensor_01)\n",
    "# alpha_01 = F.softmax(conncat_tensor_01_conv,dim=1)\n",
    "# alpha_0 = alpha_01[:,0,:]\n",
    "# alpha_1 = alpha_01[:,1,:].unsqueeze(dim=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nonblock = NonLocalBlock(in_channels= 2048)\n",
    "# temp_feature_0 = nonblock(outs[0], outs[1], alpha_1, False)\n",
    "\n",
    "\n",
    "\n",
    "# conv1 = nn.Conv1d(in_channels=2048 * 2 ,out_channels=2,kernel_size=1)\n",
    "# print(conv1(conncat_tensor_01).shape)\n",
    "\n",
    "# feature = torch.rand([2,2048,30])\n",
    "# in_channel = 2048\n",
    "# input_channels = [256,512,1024,2048]\n",
    "# attention_channels = 2048\n",
    "# outchannels = 1024\n",
    "# model = MTA(in_channel = in_channel, input_channels=input_channels,attention_channels= attention_channels,outchannels=outchannels)\n",
    "# print(model)\n",
    "#\n",
    "# results = model(feature)\n",
    "#\n",
    "# print(results.shape)\n",
    "\n",
    "\n",
    "in_channel = 2048\n",
    "input_channels = [256, 512, 1024, 2048]\n",
    "attention_channels = 2048\n",
    "outchannels = 512\n",
    "model = MTA(in_channel=in_channel, input_channels=input_channels, attention_channels=attention_channels,\n",
    "            outchannels=outchannels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8ccf8-ccfe-4905-a107-70474d9c5609",
   "metadata": {},
   "source": [
    "#### 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92984b4-534d-4fa5-a490-c53f16a87da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/hy-tmp/Resnet_pth/Epcoh_159_Rmse_6.803299427032471_PCC_0.2584606433517226_CCC_0.15121600196380586.pth\"))  #model.load_state_dict()函数把加载的权重复制到模型的权重中去"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2650f-cd33-4036-89e5-60696068fa88",
   "metadata": {},
   "source": [
    "### Resnet-NS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38292ff8-2684-4876-8dc7-d59be69ac253",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef575ac-5ca1-42d2-a03e-cebfbd8a3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 计算无关特征网络\n",
    "class unrelated_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(unrelated_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 2048, out_channels= 512, kernel_size=1)\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        self.maxpool_1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=512,out_channels=128,kernel_size=1)\n",
    "        self.relu_2 = nn.ReLU(True)\n",
    "        self.maxpool_2 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=1)\n",
    "        self.relu_3 = nn.ReLU(True)\n",
    "        self.maxpool_3 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X_dsn = X\n",
    "        temp1_conv1 = self.conv1(X_dsn)\n",
    "        temp1_relu = self.relu_1(temp1_conv1)\n",
    "        temp1_maxpool = self.maxpool_1(temp1_relu)\n",
    "        temp2_conv2 = self.conv2(temp1_maxpool)\n",
    "        temp2_relu = self.relu_2(temp2_conv2)\n",
    "        rough_result= self.maxpool_2(temp2_relu)\n",
    "\n",
    "        rough_result = self.conv3(rough_result)\n",
    "        rough_result = self.relu_3(rough_result)\n",
    "        rough_result = self.maxpool_3(rough_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return rough_result\n",
    "\n",
    "# 计算精细特征网络\n",
    "class related_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(related_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2048, out_channels=512, kernel_size=1)\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        self.maxpool_1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=512, out_channels=128, kernel_size=1)\n",
    "        self.relu_2 = nn.ReLU(True)\n",
    "        self.maxpool_2 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=1)\n",
    "        self.relu_3 = nn.ReLU(True)\n",
    "        self.maxpool_3 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        X_dsn = X\n",
    "        temp1_conv1 = self.conv1(X_dsn)\n",
    "        temp1_relu = self.relu_1(temp1_conv1)\n",
    "        temp1_maxpool = self.maxpool_1(temp1_relu)\n",
    "        temp2_conv2 = self.conv2(temp1_maxpool)\n",
    "        temp2_relu = self.relu_2(temp2_conv2)\n",
    "        smooth_result = self.maxpool_2(temp2_relu)\n",
    "\n",
    "        smooth_result = self.conv3(smooth_result)\n",
    "        smooth_result = self.relu_3(smooth_result)\n",
    "        smooth_result = self.maxpool_3(smooth_result)\n",
    "\n",
    "\n",
    "        return smooth_result\n",
    "#输入数据为精细特征，预测结果\n",
    "class predict_part(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(predict_part, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=32,out_features=1)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.fc2 = nn.Linear(in_features=64,out_features=1)\n",
    "    def forward(self,x):\n",
    "        x_in = x.reshape(x.shape[0],-1)\n",
    "        x_in = self.relu(x_in)\n",
    "        predict_temp1 = self.fc1(x_in)\n",
    "        # predict_temp2 = self.relu(predict_temp1)\n",
    "        # predict_result = self.relu(self.fc2(predict_temp2))\n",
    "\n",
    "        return predict_temp1\n",
    "#特征复原。。\n",
    "class encoder_image(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder_image, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=32, out_channels=128, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=512, kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=512, out_channels=2048, kernel_size=1)\n",
    "\n",
    "    def forward(self, smooth_feature, rough_feature):\n",
    "        encode_feature = torch.add(smooth_feature, rough_feature)\n",
    "        encode_1 = self.conv1(encode_feature)\n",
    "        x_hat = self.conv2(encode_1)\n",
    "\n",
    "        x_hat = self.conv3(x_hat)\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "\n",
    "class DSN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSN, self).__init__()\n",
    "        self.unrelated_conv = unrelated_conv()\n",
    "        self.related_conv = related_conv()\n",
    "        self.predict_part = predict_part()\n",
    "        self.encoder = encoder_image()\n",
    "\n",
    "    def forward(self,X_feature):\n",
    "\n",
    "        unrealted_data = self.unrelated_conv(X_feature)\n",
    "\n",
    "\n",
    "        realted_data = self.related_conv(X_feature)\n",
    "\n",
    "\n",
    "        predict_result  = self.predict_part(realted_data)\n",
    "\n",
    "\n",
    "        encode_result = self.encoder(unrealted_data, realted_data)\n",
    "\n",
    "        return unrealted_data, realted_data, predict_result, encode_result\n",
    "\n",
    "# model = DSN()\n",
    "# x = torch.rand([600,1,2048])\n",
    "# x = x.permute(0,2,1)\n",
    "# print(f'x:{x.shape}')\n",
    "# unrealted_data, realted_data, predict_result, encode_result = model(x)\n",
    "# print(f'unrealted_data:{unrealted_data.shape}')\n",
    "# print(f'predict_Result :{predict_result.shape}')\n",
    "# print(f'related_data:{realted_data.shape}')\n",
    "# print(f'encode_result:{encode_result.shape}')\n",
    "model = DSN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c19b7-3d05-436d-b8f7-fd98a882b88b",
   "metadata": {},
   "source": [
    "#### 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b1bc1d-f8ce-4a18-a4c6-30b7cee36124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/hy-tmp/Resnet_pth/Epcoh_1049_Rmse_6.62206506729126_PCC_0.2721236440806091_CCC_0.16563803434174354.pth\"))  #model.load_state_dict()函数把加载的权重复制到模型的权重中去"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7add7-e81a-44f5-b144-4474df809eaa",
   "metadata": {},
   "source": [
    "### AU-MTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09ffdf-af21-4923-8b9d-0b31add43dc2",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e0881a-e946-4870-b429-5ca3891f005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "## input_channels = [256,512,1024,2048]\n",
    "## attention_channels = 2048\n",
    "\n",
    "\n",
    "\n",
    "class MTB(nn.Module):\n",
    "    def __init__(self,in_channel,input_channels,attention_channels,outchannels):\n",
    "        super(MTB, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        ## 定义多个channels，得到多尺度特征【Batch，256，1】，【Batch，512，1】，【Batch，1024，1】，【Batch，2048，1】\n",
    "        self.conv1 =  nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part = nn.Sequential(\n",
    "\n",
    "                nn.Conv1d(in_channels=in_channel, out_channels=i, kernel_size=1),\n",
    "                nn.BatchNorm1d(i),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv1.append(temp_part)\n",
    "\n",
    "        self.conv2 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=i, out_channels=attention_channels, kernel_size=1),\n",
    "                nn.BatchNorm1d(attention_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv2.append(temp_part_2)\n",
    "        self.conv4 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_4 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=attention_channels, out_channels=outchannels, kernel_size=1),\n",
    "                nn.BatchNorm1d(outchannels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv4.append(temp_part_4)\n",
    "\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(in_features=outchannels * len(self.input_channels) * 30, out_features= 4096 ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            \n",
    "            nn.Linear(in_features=4096 , out_features= 512 ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            \n",
    "            nn.Linear(512,1)\n",
    "     \n",
    "            \n",
    "        )\n",
    "\n",
    "\n",
    "    def  forward(self,x):\n",
    "        outs = [in_channel(x) for in_channel in self.conv1]\n",
    "        outs = [in_channel(outs[idx])for idx,in_channel in enumerate(self.conv2)]\n",
    "\n",
    "        outs = [in_channel(outs[idx]) for idx, in_channel in enumerate(self.conv4)]\n",
    "\n",
    "        input_feature = torch.cat(outs,dim = 1 )\n",
    "        input_feature = input_feature.view(input_feature.shape[0],-1)\n",
    "        outs = self.reg(input_feature)\n",
    "\n",
    "\n",
    "        return outs\n",
    "\n",
    "\n",
    "####　测试部分\n",
    "## 现在我们得到了多个尺度的特征\n",
    "\n",
    "\n",
    "\n",
    "# feature = torch.rand([2,2048,30])\n",
    "# in_channel = 2048\n",
    "# input_channels = [256,512,1024,2048]\n",
    "# attention_channels = 2048\n",
    "# outchannels = 1024\n",
    "# model = MTB(in_channel = in_channel, input_channels=input_channels,attention_channels= attention_channels,outchannels=outchannels)\n",
    "# print(model)\n",
    "# \n",
    "# results = model(feature)\n",
    "# #\n",
    "# print(results.shape)\n",
    "\n",
    "### \n",
    "in_channel = 31\n",
    "input_channels = [4, 8, 16, 31]\n",
    "attention_channels = 16\n",
    "outchannels = 16\n",
    "model = MTB(in_channel=in_channel, input_channels=input_channels, attention_channels=attention_channels,\n",
    "            outchannels=outchannels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a1e2c-0b4f-4ac3-9bd4-4b9eb18afa16",
   "metadata": {},
   "source": [
    "#### 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29991138-ea54-46af-9159-49152a3afef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/hy-tmp/AU_pth/Epcoh_90_Rmse_6.157999515533447_PCC_0.3665695023234526_CCC_0.24920727533836307.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23857cb6-7648-4e2e-b23b-438621cbedfe",
   "metadata": {},
   "source": [
    "### AU-MTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724489e-3858-47a0-9baf-5f6be908c91d",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "713e90b3-c4fb-4d53-aee5-264e43bc3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "## input_channels = [256,512,1024,2048]\n",
    "## attention_channels = 2048\n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    \"\"\" NonLocalBlock Module\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "\n",
    "        conv_nd = nn.Conv1d\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = self.in_channels // 2\n",
    "\n",
    "        self.ImageAfterASPP_bnRelu = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.DepthAfterASPP_bnRelu = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.R_g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        self.R_theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.R_phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.R_W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.F_g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        self.F_theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.F_phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.F_W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, self_fea, mutual_fea, alpha, selfImage):\n",
    "\n",
    "        if selfImage:\n",
    "\n",
    "            selfNonLocal_fea = self.ImageAfterASPP_bnRelu(self_fea)\n",
    "            mutualNonLocal_fea = self.DepthAfterASPP_bnRelu(mutual_fea)\n",
    "\n",
    "            batch_size = selfNonLocal_fea.size(0)\n",
    "            g_x = self.R_g(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            g_x = g_x.permute(0, 2, 1)\n",
    "            # using mutual feature to generate attention\n",
    "            theta_x = self.F_theta(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            phi_x = self.F_phi(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "            # using self feature to generate attention\n",
    "            self_theta_x = self.R_theta(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_theta_x = self_theta_x.permute(0, 2, 1)\n",
    "            self_phi_x = self.R_phi(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_f = torch.matmul(self_theta_x, self_phi_x)\n",
    "            # add self_f and mutual f\n",
    "            f_div_C = F.softmax(alpha * f + self_f, dim=-1)\n",
    "            y = torch.matmul(f_div_C, g_x)\n",
    "            y = y.permute(0, 2, 1).contiguous()\n",
    "            y = y.view(batch_size, self.inter_channels, *selfNonLocal_fea.size()[2:])\n",
    "            W_y = self.R_W(y)\n",
    "            z = W_y + self_fea\n",
    "            return z\n",
    "\n",
    "        else:\n",
    "            selfNonLocal_fea = self.DepthAfterASPP_bnRelu(self_fea)## [30,2408,1]\n",
    "\n",
    "\n",
    "            mutualNonLocal_fea = self.ImageAfterASPP_bnRelu(mutual_fea)##[30,2048,1]\n",
    "\n",
    "            batch_size = selfNonLocal_fea.size(0) ##30\n",
    "\n",
    "            g_x = self.F_g(selfNonLocal_fea).view(batch_size, self.inter_channels, -1) ##[30,1,1024]\n",
    "            g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "            # using mutual feature to generate attention\n",
    "            theta_x = self.R_theta(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            phi_x = self.R_phi(mutualNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "            # using self feature to generate attention\n",
    "            self_theta_x = self.F_theta(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_theta_x = self_theta_x.permute(0, 2, 1)\n",
    "            self_phi_x = self.F_phi(selfNonLocal_fea).view(batch_size, self.inter_channels, -1)\n",
    "            self_f = torch.matmul(self_theta_x, self_phi_x)\n",
    "\n",
    "            # add self_f and mutual f\n",
    "            f_div_C = F.softmax(alpha * f + self_f, dim=-1)\n",
    "            print(g_x.shape)\n",
    "            print(f_div_C.shape)\n",
    "            y = torch.matmul(f_div_C, g_x)\n",
    "            y = y.permute(0, 2, 1).contiguous()\n",
    "            y = y.view(batch_size, self.inter_channels, *selfNonLocal_fea.size()[2:])\n",
    "            W_y = self.F_W(y)\n",
    "            z = W_y + self_fea\n",
    "            return z\n",
    "\n",
    "class MTA(nn.Module):\n",
    "    def __init__(self,in_channel,input_channels,attention_channels,outchannels):\n",
    "        super(MTA, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        ## 定义多个channels，得到多尺度特征【Batch，256，1】，【Batch，512，1】，【Batch，1024，1】，【Batch，2048，1】\n",
    "        self.conv1 =  nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part = nn.Sequential(\n",
    "\n",
    "                nn.Conv1d(in_channels=in_channel, out_channels=i, kernel_size=1),\n",
    "                nn.BatchNorm1d(i),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv1.append(temp_part)\n",
    "\n",
    "        self.conv2 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=i, out_channels=attention_channels, kernel_size=1),\n",
    "                nn.BatchNorm1d(attention_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv2.append(temp_part_2)\n",
    "        ## 通过attetnion 需要将他们对其到同一个尺度 return list[Batch,2048,1] * 4\n",
    "        self.conv3 = nn.Conv1d(in_channels= attention_channels *2,out_channels=2, kernel_size=1)\n",
    "        self.nonblock = NonLocalBlock(in_channels= attention_channels)\n",
    "        self.conv4 = nn.ModuleList()\n",
    "        for i in input_channels:\n",
    "            temp_part_4 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=attention_channels, out_channels=outchannels, kernel_size=1),\n",
    "                nn.BatchNorm1d(outchannels),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            self.conv4.append(temp_part_4)\n",
    "\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(in_features=outchannels * len(self.input_channels) * 30, out_features= 2048 ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048,1)\n",
    "        )\n",
    "\n",
    "        # self.conv4 = nn.ModuleList([nn.Conv1d(in_channels= attention_channels,out_channels=outchannels,kernel_size=1) for i in range(len(input_channels))])\n",
    "\n",
    "    def  forward(self,x):\n",
    "        outs = [in_channel(x) for in_channel in self.conv1]\n",
    "        outs = [in_channel(outs[idx])for idx,in_channel in enumerate(self.conv2)]\n",
    "\n",
    "        if len(self.input_channels) == 4:\n",
    "            conncat_tensor_01 = torch.cat([outs[0], outs[1]], dim=1)\n",
    "            conncat_tensor_01_conv = self.conv3(conncat_tensor_01)\n",
    "            alpha_01 = F.softmax(conncat_tensor_01_conv,dim=1)\n",
    "            alpha_01_1 = alpha_01[:,1,:].unsqueeze(dim=2)\n",
    "            feature_attention_0 = self.nonblock(outs[0], outs[1], alpha_01_1, True)\n",
    "\n",
    "            conncat_tensor_12 = torch.cat([outs[1], outs[2]], dim=1)\n",
    "            conncat_tensor_12_conv = self.conv3(conncat_tensor_12)\n",
    "            alpha_12 = F.softmax(conncat_tensor_12_conv, dim=1)\n",
    "            alpha_12_2 = alpha_12[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_1 = self.nonblock(outs[1], outs[2], alpha_12_2, True)\n",
    "\n",
    "            conncat_tensor_23 = torch.cat([outs[2], outs[3]], dim=1)\n",
    "            conncat_tensor_23_conv = self.conv3(conncat_tensor_23)\n",
    "            alpha_23 = F.softmax(conncat_tensor_23_conv, dim=1)\n",
    "            alpha_23_3 = alpha_23[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_2 = self.nonblock(outs[2], outs[3], alpha_23_3, True)\n",
    "\n",
    "            conncat_tensor_30 = torch.cat([outs[3], outs[0]], dim=1)\n",
    "            conncat_tensor_30_conv = self.conv3(conncat_tensor_30)\n",
    "            alpha_30 = F.softmax(conncat_tensor_30_conv, dim=1)\n",
    "            alpha_30_3 = alpha_30[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_3 = self.nonblock(outs[3], outs[0], alpha_30_3, True)\n",
    "\n",
    "            outs = [feature_attention_0, feature_attention_1, feature_attention_2, feature_attention_3]\n",
    "        elif len(self.input_channels) == 3:\n",
    "            conncat_tensor_01 = torch.cat([outs[0], outs[1]], dim=1)\n",
    "            conncat_tensor_01_conv = self.conv3(conncat_tensor_01)\n",
    "            alpha_01 = F.softmax(conncat_tensor_01_conv, dim=1)\n",
    "            alpha_01_1 = alpha_01[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_0 = self.nonblock(outs[0], outs[1], alpha_01_1, True)\n",
    "\n",
    "            conncat_tensor_12 = torch.cat([outs[1], outs[2]], dim=1)\n",
    "            conncat_tensor_12_conv = self.conv3(conncat_tensor_12)\n",
    "            alpha_12 = F.softmax(conncat_tensor_12_conv, dim=1)\n",
    "            alpha_12_2 = alpha_12[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_1 = self.nonblock(outs[1], outs[2], alpha_12_2, True)\n",
    "\n",
    "            conncat_tensor_20 = torch.cat([outs[2], outs[0]], dim=1)\n",
    "            conncat_tensor_20_conv = self.conv2(conncat_tensor_20)\n",
    "            alpha_20 = F.softmax(conncat_tensor_20_conv, dim=1)\n",
    "            alpha_20_2 = alpha_20[:, 1, :].unsqueeze(dim=2)\n",
    "            feature_attention_2 = self.nonblock(outs[2], outs[0], alpha_20_2, True)\n",
    "\n",
    "            outs = [feature_attention_0, feature_attention_1, feature_attention_2]\n",
    "\n",
    "        outs = [in_channel(outs[idx]) for idx, in_channel in enumerate(self.conv4)]\n",
    "\n",
    "        input_feature = torch.cat(outs,dim = 1 )\n",
    "        input_feature = input_feature.view(input_feature.shape[0],-1)\n",
    "        outs = self.reg(input_feature)\n",
    "\n",
    "\n",
    "        return outs\n",
    "\n",
    "\n",
    "####　测试部分\n",
    "## 现在我们得到了多个尺度的特征\n",
    "#\n",
    "# x1 = torch.rand([30,2048,1])\n",
    "# x2 = torch.rand([30,2048,1])\n",
    "# x3 = torch.rand([30,2048,1])\n",
    "# x4 = torch.rand([30,2048,1])\n",
    "# outs = [x1,x2,x3,x4]\n",
    "# ### 1. concat feature\n",
    "#\n",
    "# conncat_tensor_01 = torch.cat([outs[0], outs[1]], dim=1)\n",
    "# print(conncat_tensor_01.shape)\n",
    "# conv1 = nn.Conv1d(in_channels=2048 *2 , out_channels=2, kernel_size=1)\n",
    "# conncat_tensor_01_conv = conv1(conncat_tensor_01)\n",
    "# alpha_01 = F.softmax(conncat_tensor_01_conv,dim=1)\n",
    "# alpha_0 = alpha_01[:,0,:]\n",
    "# alpha_1 = alpha_01[:,1,:].unsqueeze(dim=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nonblock = NonLocalBlock(in_channels= 2048)\n",
    "# temp_feature_0 = nonblock(outs[0], outs[1], alpha_1, False)\n",
    "\n",
    "\n",
    "\n",
    "# conv1 = nn.Conv1d(in_channels=2048 * 2 ,out_channels=2,kernel_size=1)\n",
    "# print(conv1(conncat_tensor_01).shape)\n",
    "\n",
    "# feature = torch.rand([2,2048,30])\n",
    "# in_channel = 2048\n",
    "# input_channels = [256,512,1024,2048]\n",
    "# attention_channels = 2048\n",
    "# outchannels = 1024\n",
    "# model = MTA(in_channel = in_channel, input_channels=input_channels,attention_channels= attention_channels,outchannels=outchannels)\n",
    "# print(model)\n",
    "#\n",
    "# results = model(feature)\n",
    "#\n",
    "# print(results.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### AU\n",
    "in_channel = 31\n",
    "input_channels = [4, 8, 16, 31]\n",
    "attention_channels = 8\n",
    "outchannels = 16\n",
    "model = MTA(in_channel=in_channel, input_channels=input_channels, attention_channels=attention_channels,\n",
    "            outchannels=outchannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3e42f-c288-4430-8c4d-dd7cb8a889ed",
   "metadata": {},
   "source": [
    "#### 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e653c58-d4cf-4cad-8816-8d38a8ab1d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/hy-tmp/AU_pth/Epcoh_171_Rmse_6.135608673095703_PCC_0.38557139188424844_CCC_0.21280180728989406.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601e3dd-fa40-43b5-a452-3d345dabc449",
   "metadata": {},
   "source": [
    "### AU-NS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7166d51-c36a-4188-b509-001fdc8e7e96",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d847c39d-5aff-4b5c-b7c3-03184cc1343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 计算无关特征网络\n",
    "class unrelated_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(unrelated_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 2048, out_channels= 512, kernel_size=1)\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        self.maxpool_1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=512,out_channels=128,kernel_size=1)\n",
    "        self.relu_2 = nn.ReLU(True)\n",
    "        self.maxpool_2 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=1)\n",
    "        self.relu_3 = nn.ReLU(True)\n",
    "        self.maxpool_3 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X_dsn = X\n",
    "        temp1_conv1 = self.conv1(X_dsn)\n",
    "        temp1_relu = self.relu_1(temp1_conv1)\n",
    "        temp1_maxpool = self.maxpool_1(temp1_relu)\n",
    "        temp2_conv2 = self.conv2(temp1_maxpool)\n",
    "        temp2_relu = self.relu_2(temp2_conv2)\n",
    "        rough_result= self.maxpool_2(temp2_relu)\n",
    "\n",
    "        rough_result = self.conv3(rough_result)\n",
    "        rough_result = self.relu_3(rough_result)\n",
    "        rough_result = self.maxpool_3(rough_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return rough_result\n",
    "\n",
    "# 计算精细特征网络\n",
    "class related_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(related_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2048, out_channels=512, kernel_size=1)\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        self.maxpool_1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=512, out_channels=128, kernel_size=1)\n",
    "        self.relu_2 = nn.ReLU(True)\n",
    "        self.maxpool_2 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=1)\n",
    "        self.relu_3 = nn.ReLU(True)\n",
    "        self.maxpool_3 = nn.MaxPool1d(kernel_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        X_dsn = X\n",
    "        temp1_conv1 = self.conv1(X_dsn)\n",
    "        temp1_relu = self.relu_1(temp1_conv1)\n",
    "        temp1_maxpool = self.maxpool_1(temp1_relu)\n",
    "        temp2_conv2 = self.conv2(temp1_maxpool)\n",
    "        temp2_relu = self.relu_2(temp2_conv2)\n",
    "        smooth_result = self.maxpool_2(temp2_relu)\n",
    "\n",
    "        smooth_result = self.conv3(smooth_result)\n",
    "        smooth_result = self.relu_3(smooth_result)\n",
    "        smooth_result = self.maxpool_3(smooth_result)\n",
    "\n",
    "\n",
    "        return smooth_result\n",
    "#输入数据为精细特征，预测结果\n",
    "class predict_part(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(predict_part, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=32,out_features=1)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.fc2 = nn.Linear(in_features=64,out_features=1)\n",
    "    def forward(self,x):\n",
    "        x_in = x.reshape(x.shape[0],-1)\n",
    "        x_in = self.relu(x_in)\n",
    "        predict_temp1 = self.fc1(x_in)\n",
    "        # predict_temp2 = self.relu(predict_temp1)\n",
    "        # predict_result = self.relu(self.fc2(predict_temp2))\n",
    "\n",
    "        return predict_temp1\n",
    "#特征复原。。\n",
    "class encoder_image(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder_image, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=32, out_channels=128, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=512, kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=512, out_channels=2048, kernel_size=1)\n",
    "\n",
    "    def forward(self, smooth_feature, rough_feature):\n",
    "        encode_feature = torch.add(smooth_feature, rough_feature)\n",
    "        encode_1 = self.conv1(encode_feature)\n",
    "        x_hat = self.conv2(encode_1)\n",
    "\n",
    "        x_hat = self.conv3(x_hat)\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "\n",
    "class DSN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSN, self).__init__()\n",
    "        self.unrelated_conv = unrelated_conv()\n",
    "        self.related_conv = related_conv()\n",
    "        self.predict_part = predict_part()\n",
    "        self.encoder = encoder_image()\n",
    "\n",
    "    def forward(self,X_feature):\n",
    "\n",
    "        unrealted_data = self.unrelated_conv(X_feature)\n",
    "\n",
    "\n",
    "        realted_data = self.related_conv(X_feature)\n",
    "\n",
    "\n",
    "        predict_result  = self.predict_part(realted_data)\n",
    "\n",
    "\n",
    "        encode_result = self.encoder(unrealted_data, realted_data)\n",
    "\n",
    "        return unrealted_data, realted_data, predict_result, encode_result\n",
    "\n",
    "# model = DSN()\n",
    "# x = torch.rand([600,1,2048])\n",
    "# x = x.permute(0,2,1)\n",
    "# print(f'x:{x.shape}')\n",
    "# unrealted_data, realted_data, predict_result, encode_result = model(x)\n",
    "# print(f'unrealted_data:{unrealted_data.shape}')\n",
    "# print(f'predict_Result :{predict_result.shape}')\n",
    "# print(f'related_data:{realted_data.shape}')\n",
    "# print(f'encode_result:{encode_result.shape}')\n",
    "model = DSN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9046e3-5c95-4860-b03c-8c82044bbcbd",
   "metadata": {},
   "source": [
    "#### 读取权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8be9d5c-2c27-4b18-8d0c-6d3426dade3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/hy-tmp/AU_pth/Epcoh_4678_Rmse_6.085559368133545_PCC_0.41137230431761634_CCC_0.26710996359867084.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e521c-88af-4fdd-91f9-c2a2a2ed8a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
